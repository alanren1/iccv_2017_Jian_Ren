\section{Datasets}

%Existing aesthetics datasets either do not have rater identities\cite{murray2012ava} or have a limited number of annotated images\cite{kong2016photo}, thus are not suitable for the personalized aesthetics study. To overcome such limitations, we collected two new datasets and will later release them promote research investigation.
%\vspace{-0.15in}


\paragraph{FLICKR-AES} We download 40,000 photos with a creative commons license from Flickr\footnote{https://www.flickr.com} and collect their aesthetic ratings through AMT. The raw aesthetics scores range from 1 to 5 representing the lowest to the highest aesthetics level. Each image is rated by five different AMT workers and its ground truth aesthetics label is approximated to be the average of the five scores. In total, 210 AMT workers participated in the annotation of FLICKR-AES. 

We split the dataset into training and testing sets. Specifically, we select 4,737 images labeled by 37 AMT workers to include in the testing set. The number of photos each testing worker labeled ranges from 105 to 171 (avg. = 137). All the remaining 35,263 images annotated by the rest 173 workers are included in the training set. We leverage the latter for training both generic and personalized aesthetics models. With this split, we verified that the testing set does not have any images labeled by the workers in the training set, and vice versa. This allows us to simulate real application scenarios where each user only provide ratings on his or her own photos, and the algorithm cannot access those photos and ratings beforehand.

Compared to the existing aesthetics dataset with rater identities~\cite{kong2016photo}, FLICKR-AES is a much larger and more comprehensive dataset which has a more diverse and balanced coverage of contents. 

\paragraph{REAL-CUR}
In FLICKR-AES, aesthetics ratings are provided by AMT workers instead of actual owners of the photos in the dataset. For testing in the context of real-world personal photo ranking and curation applications, we collect another dataset composed of 14 personal albums (all from different people) and corresponding aesthetic ratings provided by the owners of the albums. The number of photos in each album ranges from 197 to 222 while the average is 205. As we only have one user rating for each photo, we instructed each user to go through their album multiple times to make the ratings consistent. To the best of our knowledge, this is the first aesthetics analysis dataset with real users' ratings on their own photos. We will make those datasets publicly available. More details and example images regarding the datasets are shown in the supplementary materials.



\section{Analysis of User Preferences}\label{analysis}
How significant are individual user's preferences relative to generic aesthetic perception? How are those preferences related to image attributes? In order to answer these questions, we perform the following correlation analysis between individual user's ratings and various image attributes using FLICKR-AES.

There are numerous image properties or attributes which could affect a user's aesthetics rating. Among them, we choose content attributes (semantic categories) and aesthetics attributes (e.g. rule-of-third, symmetry) as they are the most representative cues explored for aesthetics analysis and are proved effective for predicting aesthetic quality of an image\cite{dhar2011high, luo2011content}. We show  details on how to extract those attributes in Section~\ref{PAM}. 

We select 111 AMT workers from the training set who have labeled at least 172 images (avg. = 1,550), and treat them as individual users. For each user, to measure the correlation of the preference and the content/aesthetics attributes, we use Spearman's rank correlation ($\rho$) \cite{myers2010research} which is calculated as $\rho = 1 - 6\frac{\sum_{i=1}^{N}{(r_i - r_{i}^{'})}^2}{N^3 - N}$, where $r_i$ is the rank of the $i$-th item when sorting the scores given by the first metric in descending order and $r_{i}^{'}$ is the rank for the scores given by the second metric. $\rho$ ranges from -1 to 1 and a higher absolute value indicates stronger correlation between the first metric and the second metric. 

Directly measuring the correlation between user's absolute aesthetics scores and image attributes cannot properly reflect user's preference, as the correlation values in this case are dominated by the average ratings of each image. Therefore, we compute the offset (or residual) of a user's score to the ground truth (average) score, and measure correlation between offset values and image attributes instead. We randomly select 8 AMT workers and show the results in Figure~\ref{corrEx}, in which dark red color indicates a user prefers these attributes, while dark blur color means the user has relatively lower scores on images with those attributes. It clearly shows that the deviation of each user's ratings (w.r.t. image attributes) are unique. We further visualize example images rated by Worker1 and Worker4 in Figure~\ref{turker1_4}. As we can see, Worker1 prefers landscape images versus images of crowds while Worker4 prefers images with symmetry attributes over images of people. 

To understand the significance of the correlation versus randomness of users' labels, we additionally create two ``random '' users as the baseline. The two random users are generated by randomly sampling 1,000 images from the training set as their annotated images. The score for each image is set to the ground-truth score (i.e. the average rating of five AMT workers) perturbed by a zero-mean Gaussian random noise with standard deviation of 0.2 and 2, respectively. We choose those standard deviations to simulate two ``average'' users with a relatively small and a relatively large amount of label offsets deviated from the generic scores.
The correlations of their offsets with attributes are also included in Figure~\ref{corrEx}, which show no statistically meaningful preference as expected. Compared with ``random'' users, the correlations on actual users are much stronger, demonstrating that their preferences are indeed related to content and aesthetics attributes instead of random deviations.

For each user, we also compute the sum of the absolute values of the correlation and compare the value with two random users. We run the experiments for 50 times and report the average for the two ``random'' users. We find all the 111 actual users have higher average correlation scores than the ``random'' users, showing that the correlations are statistically meaningful. 

The analysis demonstrates that score offsets are very effective cues revealing user preferences regarding aesthetics on content and aesthetics attributes. Motivated by this, we derive a novel residual (offset)-based model for learning personalized aesthetics in the next section. 
%We calculate the ranking corrleation between the with the 

